# 2026-02-04 Experiment Log

## Goal
Optimize spam/scam classifier for crypto and scam detection. Minimize FPR (don't flag legit posts), maximize detection. Promo detection deprioritized.

## Constraints
- FPR < 2% (ideally < 1%) is top priority
- Focus only on crypto and scam - ignore promo

---

## 10:00 - Time-based splits created

Created proper temporal train/calib/holdout splits to avoid data leakage.

```bash
python scripts/make_time_splits.py
```

**Output:**
- `data/train_time.txt` - 2097 samples (training)
- `data/calib.txt` - 261 samples (calibration)
- `data/holdout_time.txt` - 261 samples (holdout, most recent)

---

## 10:30 - Hyperparameter grid search

Trained 8 model configurations varying word n-grams, char n-grams, and learning rate.

| Model | wordNgrams | minn/maxn | lr |
|-------|------------|-----------|-----|
| grid_w1_c25_lr0.2 | 1 | 2/5 | 0.2 |
| grid_w1_c25_lr0.5 | 1 | 2/5 | 0.5 |
| grid_w1_c36_lr0.2 | 1 | 3/6 | 0.2 |
| grid_w1_c36_lr0.5 | 1 | 3/6 | 0.5 |
| grid_w2_c36_lr0.2 | 2 | 3/6 | 0.2 |
| grid_w3_c25_lr0.2 | 3 | 2/5 | 0.2 |

**Training command (example):**
```bash
python scripts/train_fasttext.py \
  --train data/train_time.txt \
  --model-out models/experiments/grid_w1_c25_lr0.2.bin \
  --word-ngrams 1 \
  --lr 0.2
```

---

## 11:00 - Model evaluation on holdout

Evaluated all models with per-label FPR targets.

**Winner: `grid_w1_c25_lr0.2`** - best crypto recall under FPR <= 2%

---

## 19:00 - Final threshold tuning

Tuned thresholds on holdout with differentiated FPR targets:
- Crypto: 2% FPR target
- Scam: 1% FPR target
- Promo: disabled (threshold = 1.0)

```bash
python scripts/tune_thresholds_fpr.py \
  --model models/experiments/grid_w1_c25_lr0.2.bin \
  --data data/holdout_time.txt \
  --out models/experiments/grid_w1_c25_lr0.2.holdout_mix_fpr.thresholds.json \
  --target-fpr-crypto 0.02 \
  --target-fpr-scam 0.01
```

---

## Final Results

**Model:** `models/experiments/grid_w1_c25_lr0.2.bin` (768MB)
**Thresholds:** `models/experiments/grid_w1_c25_lr0.2.holdout_mix_fpr.thresholds.json`

| Label | Precision | Recall | FPR | Threshold |
|-------|-----------|--------|-----|-----------|
| Crypto | 0.993 | 0.837 (139/166) | 1.05% | 0.8176 |
| Scam | 0.965 | 0.277 (28/101) | 0.63% | 0.9450 |
| Promo | - | - | - | 1.0 (disabled) |

---

## Artifacts Created

**Scripts:**
- `scripts/make_time_splits.py`
- `scripts/mine_hard_negatives_txt.py`
- `scripts/build_rebalanced_calib.py`
- `scripts/tune_thresholds_fpr.py`

**Data (not committed, regenerate from scripts):**
- `data/train_time.txt`
- `data/calib.txt`
- `data/holdout_time.txt`
- Various rebalanced calibration sets

**Models (not committed, 768MB each):**
- `models/experiments/grid_w1_c25_lr0.2.bin` ← **selected**
- 7 other grid search variants

**Documentation:**
- `docs/CALIBRATION_FIX_REPORT.md`
- `docs/EVAL_RESULTS.md`

---

## Next Steps

1. [ ] Quantize model for extension (768MB → ~100MB)
2. [ ] Wire as production default OR rebuild calibration without holdout data
3. [ ] Delete unused experiment models to save space

---

## 21:00 - Quantization for browser extension

Quantized `grid_w1_c25_lr0.2.bin` using `scripts/reduce_fasttext.py`.

```bash
python scripts/reduce_fasttext.py \
  --model models/experiments/grid_w1_c25_lr0.2.bin \
  --valid data/holdout_time.txt \
  --out-dir models/experiments \
  --only quant-default \
  --threshold 0.945
```

**Reduced model:** `models/experiments/grid_w1_c25_lr0.2.ftz` (97MB)

### Thresholds (quantized model)
Re-tuned thresholds on holdout to keep FPR within targets:
- Crypto: FPR <= 2%
- Scam: FPR <= 1%
- Promo: disabled (threshold = 1.0)

**Threshold file:** `models/experiments/grid_w1_c25_lr0.2.ftz.thresholds.json`

### Holdout Results (data/holdout_time.txt)
Using quantized model + updated thresholds:

| Label | Precision | Recall | FPR | Threshold |
|-------|-----------|--------|-----|-----------|
| Crypto | 0.991 | 0.639 (106/166) | 1.05% | 0.9450 |
| Scam | 0.968 | 0.297 (30/101) | 0.63% | 0.9859 |
| Promo | - | - | - | 1.0 (disabled) |

**Delta vs full .bin:**
- Crypto recall dropped from 0.837 → 0.639 under FPR < 2%
- Scam recall roughly flat (0.267 → 0.297) with FPR still < 1%

### Production Update
- Copied reduced model to `models/scam_detector.ftz`
- Updated `config/thresholds.json` to match quantized thresholds


---

## 22:09 - Full quantization grid (<=10MB target)

Quantized `grid_w1_c25_lr0.2.bin` using `scripts/reduce_fasttext.py` (via module) across full grid. Metrics computed on `data/holdout_time.txt` with per-label thresholds maximizing recall under FPR <= 2% (crypto + scam). Models retained on disk only if size <= 10MB and both labels meet FPR <= 2%.

| cutoff | dsub | qout | qnorm | size_mb | crypto_thr | crypto_prec | crypto_rec | crypto_fpr | scam_thr | scam_prec | scam_rec | scam_fpr | kept | notes |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| 1000 | 1 | 0 | 0 | 0.20 | 0.7773 | 0.993 | 0.886 | 0.011 | 0.9149 | 0.919 | 0.337 | 0.019 | yes |  |
| 1000 | 1 | 0 | 1 | 0.20 | 0.7432 | 0.993 | 0.886 | 0.011 | 0.9047 | 0.919 | 0.337 | 0.019 | yes |  |
| 1000 | 1 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 1000 | 1 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 1000 | 2 | 0 | 0 | 0.15 | 0.7719 | 0.993 | 0.886 | 0.011 | 0.9149 | 0.919 | 0.337 | 0.019 | yes |  |
| 1000 | 2 | 0 | 1 | 0.16 | 0.7249 | 0.993 | 0.886 | 0.011 | 0.9099 | 0.919 | 0.337 | 0.019 | yes |  |
| 1000 | 2 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 1000 | 2 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 1000 | 4 | 0 | 0 | 0.13 | 0.7372 | 0.993 | 0.886 | 0.011 | 0.9325 | 0.919 | 0.337 | 0.019 | yes |  |
| 1000 | 4 | 0 | 1 | 0.13 | 0.7186 | 0.993 | 0.886 | 0.011 | 0.8963 | 0.919 | 0.337 | 0.019 | yes |  |
| 1000 | 4 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 1000 | 4 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 1000 | 8 | 0 | 0 | 0.12 | 0.7432 | 0.993 | 0.892 | 0.011 | 0.9305 | 0.919 | 0.337 | 0.019 | yes |  |
| 1000 | 8 | 0 | 1 | 0.12 | 0.6860 | 0.993 | 0.886 | 0.011 | 0.9019 | 0.919 | 0.337 | 0.019 | yes |  |
| 1000 | 8 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 1000 | 8 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 5000 | 1 | 0 | 0 | 0.62 | 0.8840 | 0.993 | 0.855 | 0.011 | 0.9526 | 0.914 | 0.317 | 0.019 | yes |  |
| 5000 | 1 | 0 | 1 | 0.62 | 0.8439 | 0.993 | 0.867 | 0.011 | 0.9604 | 0.941 | 0.317 | 0.013 | yes |  |
| 5000 | 1 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 5000 | 1 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 5000 | 2 | 0 | 0 | 0.38 | 0.8775 | 0.993 | 0.855 | 0.011 | 0.9526 | 0.914 | 0.317 | 0.019 | yes |  |
| 5000 | 2 | 0 | 1 | 0.38 | 0.8559 | 0.993 | 0.861 | 0.011 | 0.9566 | 0.914 | 0.317 | 0.019 | yes |  |
| 5000 | 2 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 5000 | 2 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 5000 | 4 | 0 | 0 | 0.26 | 0.8520 | 0.993 | 0.867 | 0.011 | 0.9669 | 0.941 | 0.317 | 0.013 | yes |  |
| 5000 | 4 | 0 | 1 | 0.26 | 0.8559 | 0.993 | 0.861 | 0.011 | 0.9553 | 0.914 | 0.317 | 0.019 | yes |  |
| 5000 | 4 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 5000 | 4 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 5000 | 8 | 0 | 0 | 0.20 | 0.8439 | 0.993 | 0.867 | 0.011 | 0.9669 | 0.941 | 0.317 | 0.013 | yes |  |
| 5000 | 8 | 0 | 1 | 0.21 | 0.8775 | 0.993 | 0.855 | 0.011 | 0.9579 | 0.914 | 0.317 | 0.019 | yes |  |
| 5000 | 8 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 5000 | 8 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 10000 | 1 | 0 | 0 | 1.13 | 0.8597 | 0.993 | 0.855 | 0.011 | 0.9512 | 0.939 | 0.307 | 0.013 | yes |  |
| 10000 | 1 | 0 | 1 | 1.14 | 0.8597 | 0.993 | 0.819 | 0.011 | 0.9381 | 0.909 | 0.297 | 0.019 | yes |  |
| 10000 | 1 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 10000 | 1 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 10000 | 2 | 0 | 0 | 0.66 | 0.8808 | 0.993 | 0.837 | 0.011 | 0.9482 | 0.939 | 0.307 | 0.013 | yes |  |
| 10000 | 2 | 0 | 1 | 0.67 | 0.8634 | 0.993 | 0.819 | 0.011 | 0.9566 | 0.935 | 0.287 | 0.013 | yes |  |
| 10000 | 2 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 10000 | 2 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 10000 | 4 | 0 | 0 | 0.42 | 0.8808 | 0.993 | 0.831 | 0.011 | 0.9497 | 0.914 | 0.317 | 0.019 | yes |  |
| 10000 | 4 | 0 | 1 | 0.43 | 0.8706 | 0.993 | 0.819 | 0.011 | 0.9604 | 0.935 | 0.287 | 0.013 | yes |  |
| 10000 | 4 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 10000 | 4 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 10000 | 8 | 0 | 0 | 0.30 | 0.8670 | 0.993 | 0.837 | 0.011 | 0.9540 | 0.941 | 0.317 | 0.013 | yes |  |
| 10000 | 8 | 0 | 1 | 0.32 | 0.8706 | 0.993 | 0.819 | 0.011 | 0.9482 | 0.909 | 0.297 | 0.019 | yes |  |
| 10000 | 8 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 10000 | 8 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 20000 | 1 | 0 | 0 | 2.17 | 0.8706 | 0.993 | 0.807 | 0.011 | 0.9450 | 0.938 | 0.297 | 0.013 | yes |  |
| 20000 | 1 | 0 | 1 | 2.19 | 0.8439 | 0.992 | 0.795 | 0.011 | 0.9363 | 0.938 | 0.297 | 0.013 | yes |  |
| 20000 | 1 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 20000 | 1 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 20000 | 2 | 0 | 0 | 1.22 | 0.8775 | 0.992 | 0.789 | 0.011 | 0.9434 | 0.938 | 0.297 | 0.013 | yes |  |
| 20000 | 2 | 0 | 1 | 1.24 | 0.8439 | 0.992 | 0.795 | 0.011 | 0.9363 | 0.909 | 0.297 | 0.019 | yes |  |
| 20000 | 2 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 20000 | 2 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 20000 | 4 | 0 | 0 | 0.74 | 0.8670 | 0.993 | 0.813 | 0.011 | 0.9526 | 0.938 | 0.297 | 0.013 | yes |  |
| 20000 | 4 | 0 | 1 | 0.76 | 0.8597 | 0.992 | 0.771 | 0.011 | 0.9381 | 0.938 | 0.297 | 0.013 | yes |  |
| 20000 | 4 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 20000 | 4 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 20000 | 8 | 0 | 0 | 0.51 | 0.8634 | 0.993 | 0.807 | 0.011 | 0.9434 | 0.914 | 0.317 | 0.019 | yes |  |
| 20000 | 8 | 0 | 1 | 0.53 | 0.8520 | 0.992 | 0.789 | 0.011 | 0.9450 | 0.938 | 0.297 | 0.013 | yes |  |
| 20000 | 8 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 20000 | 8 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 50000 | 1 | 0 | 0 | 5.31 | 0.8439 | 0.992 | 0.789 | 0.011 | 0.9284 | 0.909 | 0.297 | 0.019 | yes |  |
| 50000 | 1 | 0 | 1 | 5.35 | 0.8267 | 0.993 | 0.867 | 0.011 | 0.9553 | 0.944 | 0.337 | 0.013 | yes |  |
| 50000 | 1 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 50000 | 1 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 50000 | 2 | 0 | 0 | 2.92 | 0.8439 | 0.992 | 0.759 | 0.011 | 0.9263 | 0.909 | 0.297 | 0.019 | yes |  |
| 50000 | 2 | 0 | 1 | 2.97 | 0.8267 | 0.993 | 0.867 | 0.011 | 0.9553 | 0.944 | 0.337 | 0.013 | yes |  |
| 50000 | 2 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 50000 | 2 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 50000 | 4 | 0 | 0 | 1.73 | 0.8520 | 0.992 | 0.765 | 0.011 | 0.9417 | 0.968 | 0.297 | 0.006 | yes |  |
| 50000 | 4 | 0 | 1 | 1.78 | 0.8312 | 0.993 | 0.861 | 0.011 | 0.9627 | 0.944 | 0.337 | 0.013 | yes |  |
| 50000 | 4 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 50000 | 4 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 50000 | 8 | 0 | 0 | 1.16 | 0.8597 | 0.992 | 0.747 | 0.011 | 0.9381 | 0.938 | 0.297 | 0.013 | yes |  |
| 50000 | 8 | 0 | 1 | 1.21 | 0.8355 | 0.993 | 0.855 | 0.011 | 0.9579 | 0.921 | 0.347 | 0.019 | yes |  |
| 50000 | 8 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 50000 | 8 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 100000 | 1 | 0 | 0 | 10.50 | 0.8597 | 0.992 | 0.777 | 0.011 | 0.9482 | 0.939 | 0.307 | 0.013 | no | discarded (FPR>2% or >10MB) |
| 100000 | 1 | 0 | 1 | 10.60 | 0.9809 | 0.990 | 0.584 | 0.011 | 0.9659 | 0.912 | 0.307 | 0.019 | no | discarded (FPR>2% or >10MB) |
| 100000 | 1 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: Matrix too small for quantization, must have at least 256 rows |
| 100000 | 1 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 2 | 0 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 2 | 0 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 2 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 2 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 4 | 0 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 4 | 0 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 4 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 4 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 8 | 0 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 8 | 0 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 8 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 100000 | 8 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 1 | 0 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 1 | 0 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 1 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 1 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 2 | 0 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 2 | 0 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 2 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 2 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 4 | 0 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 4 | 0 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 4 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 4 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 8 | 0 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 8 | 0 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 8 | 1 | 0 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |
| 200000 | 8 | 1 | 1 |  |  |  |  |  |  |  |  |  | no | error: [Errno 32] Broken pipe |

**Best under 10MB (crypto recall priority, FPR<=2%):**

- /home/bob/InternetCondom/models/experiments/quant_grid_10mb/grid_w1_c25_lr0.2_cut1000_dsub8_qout0_qnorm0.ftz
- cutoff=1000 dsub=8 qout=0 qnorm=0
- size=0.12MB
- crypto: rec=0.892 prec=0.993 fpr=0.011 thr=0.7432
- scam: rec=0.337 prec=0.919 fpr=0.019 thr=0.9305
