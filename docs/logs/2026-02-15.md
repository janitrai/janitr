---
title: Daily Log 2026-02-15
author: bob <unknown@example.com>
date: 2026-02-15
tz: Europe/Berlin
created: 2026-02-15T00:08:59+01:00
last_section: 2026-02-15T16:06:40+01:00
updated: 2026-02-15T16:06:40+01:00
---

## 00:08

Compared small transformer (`h128_l4_a4_i512`, int8 eval at `/tmp/small_h128_holdout_eval_int8.json`) against baseline transformer benchmark (`models/benchmarks/2026-02-14_expanded_holdout/transformer/student_holdout_eval_int8.json`).

Observed large gains on the shared holdout support (scam=245, clean=506, topic_crypto=318): scam recall +32.24 pts, scam F1 +21.74 pts, macro F1 +16.28 pts, exact match +14.22 pts, and lower scam FPR by 0.73 pts.

Flagged as likely needing provenance validation because gain magnitude is unusually large versus earlier transformer comparisons.

## 09:13

Backed up full local `models/` directory before commit/push to `/home/bob/model_backups/janitr_models_20260215_091229` (~32G snapshot).

Prepared commit including `data/split_backups/2026-02-14-holdout-expand/*` and todayâ€™s SimpleLog updates.

Per request, deleted oversized backup `/home/bob/model_backups/janitr_models_20260215_091229` and replaced it with a minimal backup containing only the deployable 2.0MB student int8 ONNX artifact.

New backup path: `/home/bob/model_backups/janitr_small_int8_20260215_091611/student.int8.onnx`.

## 09:30

Implemented dual-backend extension inference plumbing so Janitr can run `fasttext`, `transformer`, or `auto` backend selection without replacing the current flow.

Code changes:
- `extension/background.js`: added persisted backend config (`ic_model_backend`) via extension storage, plus runtime messages `ic-set-model-backend` and `ic-get-model-backend`; inference messages now forward selected engine to offscreen.
- `extension/offscreen.js`: added engine router with fastText path, transformer path, and `auto` fallback behavior (transformer first, then fastText if transformer fails).
- `extension/transformer/scam-detector-transformer.js` (new): ONNX runtime wrapper + BERT WordPiece tokenizer implementation in browser JS; outputs compatible Janitr result schema (`label`, `labels`, `scores`, `probability`, thresholds).
- `extension/manifest.json`: added `storage` permission and web-accessible paths for transformer/runtime assets.
- `extension/content-script.js`: now records returned inference engine/fallback metadata in debug logs.
- `.gitignore`: added ONNX/WASM binary ignore patterns.

Validation:
- Syntax checks passed with `node --check` for updated JS files.
- Playwright smoke test could not run in this environment because Chromium binary is not installed (`npx playwright install` required).

Staged local (git-ignored) transformer extension assets to make dual-backend path runnable without committing binaries:
- `extension/transformer/student.int8.onnx`
- `extension/transformer/thresholds.json`
- `extension/transformer/student_config.json`
- `extension/transformer/tokenizer/vocab.txt`
- `extension/vendor/onnxruntime-web/{ort.wasm.min.mjs,ort-wasm-simd-threaded.mjs,ort-wasm-simd-threaded.wasm}`

Updated `.gitignore` to keep these runtime/model artifacts local-only while allowing source code commits.

Attempted Node-based direct smoke run of transformer module; it failed on `fetch(file://...)` due Node undici file-scheme limitation. This does not block extension runtime (uses `chrome-extension://` URLs), but browser-side validation is still required.

## 09:36

Confirmed backend behavior: `auto` mode selects transformer first and falls back to fastText only on transformer failure.

Refactored extension naming to general classifier terminology:
- Renamed `extension/fasttext/scam-detector.js` -> `extension/fasttext/classifier.js`
- Renamed `extension/transformer/scam-detector-transformer.js` -> `extension/transformer/classifier-transformer.js`
- Renamed exports/usages to neutral API (`loadClassifierModel`, `loadClassifierThresholds`, `predictClassifier`, `resetClassifierModel`, `predictTransformerBatch`)
- Updated content-script UI/debug strings from "Scam model"/"Scam detector inference failed" to generic classifier phrasing and renamed confidence data attribute to `data-ic-confidence`
- Updated smoke tests and AGENTS.md references to new classifier names

Behavior remains unchanged aside from naming/output-key normalization (`isFlagged` instead of `isScam`).

Changed extension default classifier backend to transformer by setting `DEFAULT_ENGINE = ENGINE_TRANSFORMER` in `extension/background.js`.

Effect: when no backend is explicitly stored yet, inference requests now default to transformer path (with offscreen auto/explicit behavior unchanged).

## 09:45

Started full extension modern TypeScript migration completion pass: fixing TS compile errors in extension/src, adding global/module type declarations, and preserving runtime behavior with generated JS outputs.

## 09:52

Completed TypeScript migration of extension runtime sources under extension/src with typed implementations for background/content script/offscreen/fastText wrapper/transformer classifier.

Resolved path mapping issues by configuring extension/tsconfig.json rootDirs for source-vs-emitted tree parity.

Validation:
- npm run extension:typecheck (pass)
- npm run extension:build (pass; regenerated extension/*.js runtime artifacts)

Ran Prettier on migrated TypeScript files and re-validated extension toolchain:
- npm run extension:typecheck (pass)
- npm run extension:build (pass)
- npx prettier --check on extension TS/build configs (pass)

Generated extension runtime JS artifacts are now produced from extension/src TypeScript sources.

Attempted runtime smoke test via Playwright (extension/tests/wasm-smoke.spec.ts). Failed because Chromium binary is not installed in this environment. Error indicates running 'npx playwright install' is required before browser-level extension tests.

Committed and pushed modern TypeScript extension rewrite on feat/tiny-transformer-impl. Commit: 8ca3bde (includes TS sources, build tooling, regenerated runtime JS, and migration notes in log).

## 10:01

Clarified metric mismatch: the previously cited ~90% transformer results are from baseline-on-expanded-holdout (1069 rows), while the 2MB capacity-sweep artifact metrics came from an older 214-row holdout eval. These are different runs/splits and not directly comparable.

## 10:20

Clarified that the 3.4MB transformer int8 artifact is not the ~90% run. Frozen-split int8 metrics are exact=0.8241, macro_f1=0.8013, scam_f1=0.7407; the ~90% figures came from the higher-scoring baseline-on-expanded-holdout eval context.

## 10:31

Summarized transformer capacity-sweep size/performance tradeoff on the shared eval set (n=214):
- h128_l4_a4_i512 (1.93MB int8): scam_f1 0.7957, scam_fpr 0.0366, macro_f1 0.7998, exact 0.8131
- h192_l4_a4_i768 (3.39MB int8): scam_f1 0.7816, scam_fpr 0.0183, macro_f1 0.8065, exact 0.8224
- h256_l4_a4_i1024 (5.23MB int8): scam_f1 0.7778, scam_fpr 0.0305, macro_f1 0.8233, exact 0.8411
- h384_l4_a6_i1536 (10.02MB int8): scam_f1 0.8182, scam_fpr 0.0122, macro_f1 0.8333, exact 0.8458

Also noted production benchmark int8 baseline (3.4MB, n=1069): macro_f1 0.8013, exact 0.8241, scam_f1 0.7407, scam_fpr 0.0121.

## 11:07

Acknowledged missed process adherence: AGENTS.md includes general-visualization skill breadcrumb for metric comparison outputs, and I failed to apply it on one response. Corrective action: default to general-visualization format for future comparison prints in this repo.

Updated AGENTS.md Skill Breadcrumbs to make general-visualization usage explicit as a NON-VIOLABLE rule with MUST wording for metric comparison outputs.

Printed combined visualization request: earlier transformer capacity sweep stats plus latest fastText metrics, with aligned plain-text comparison and best-value asterisk markers; included comparability caveat about split-size mismatch.

## 11:52

Recommendation for current transformer ship candidate: use benchmark int8 model (models/benchmarks/2026-02-14_expanded_holdout/transformer/student.int8.onnx, ~3.4MB) with matching tokenizer/config/threshold artifacts because it meets size target range and keeps scam FPR near 1.2% on the clean frozen benchmark holdout.

## 12:00

Proposed long-term model artifact directory structure for ongoing transformer/fastText experiments: separate immutable runs, promoted candidates, and production pointers; keep binaries out of git and track provenance manifests/metrics in each run.

## 14:48

Clarified industry practice for model artifact organization and Hugging Face publishing: keep immutable local run registry, publish only promoted checkpoints to Hub with model card/provenance, and pin deployment to exact Hub revision SHA.

Provided concrete Hugging Face upload workflow for current transformer ship candidate: auth, repo create, stage minimal deploy artifacts (int8 onnx + tokenizer + config + thresholds + eval), upload via huggingface_hub HfApi.upload_folder, and pin deployment to commit SHA/revision.

## 14:56

Per user request, rolled back all hover-nudge intervention footprints: removed hover patch/revert entries from docs/logs/2026-02-15.md and confirmed no code diffs remain in extension/src/content-script.ts or generated extension/content-script.js.

User created Hugging Face model repo for ongoing experiments: https://huggingface.co/janitr/experiments. Treat this as the continuous experiment upload target.

## 15:06

Researched Hugging Face access controls for safe delegation: documented recommendation to use fine-grained token scoped to janitr/experiments, upload via create_pr + parent_commit, and noted HF does not expose GitHub-style branch protection in current public repo settings docs (repo/org role controls and optional PR/discussion toggles are available).

## 15:15

Provided strict HF token setup checklist from screenshot options: fine-grained token, zero broad user/org scopes, repo-specific permissions only for janitr/experiments, and PR-only upload workflow with parent_commit + unique path to prevent clobber/overwrite.

Clarified branch-protection expectation on Hugging Face: write-scoped token can still push to main; Hub supports PR workflow but no GitHub-style mandatory branch protection controls exposed in standard repository settings docs. Recommended process controls: PR-only uploads, parent_commit guard, append-only run paths, short-lived token rotation.

## 15:21

Explained no-write-token handoff workflow: agent prepares staged artifacts and exact upload command/script locally; user executes final Hugging Face upload command with private token, preserving control over main branch writes.

Added `scripts/sync_to_experiments_repo.py` to support safe handoff syncing into a local experiments repo (default dest: ~/offline/janitr-experiments).

Behavior:
- Copies benchmark transformer deployment artifacts into `runs/<run_id>/`.
- Generates `MANIFEST.json` with file hashes/sizes/provenance.
- Refuses to clobber existing run dir unless `--force`.
- Validates destination is a git repo by default (override with `--allow-non-git`).
- Supports `--dry-run` and optional `--include-fp32`.

Validation:
- dry-run to temp destination (pass)
- full copy into temp git repo (pass)
- formatted script with `uvx ruff format`.

## 15:30

Clarified execution model confusion: assistant commands run in the same workspace machine as user (/home/bob/janitr), so sync script is local copy only; for remote-server to personal-laptop transfer user must use scp/rsync separately.

Added remote-to-local sync helper script scripts/sync_experiments_from_remote.sh for user laptop workflows. Script uses rsync over SSH, supports --remote, --remote-path, --dest, optional --run-id, --dry-run, and optional --delete, and excludes .git to avoid repo metadata clobbering.

Discussed run naming preference: user wants human-friendly codename style (e.g., adjective-animal) rather than purely technical IDs. Recommended dual naming with stable technical run_id plus optional codename alias.

## 15:45

Added automatic dated run-name support across training entrypoints.

- Added `scripts/run_naming.py` helper (`resolve_run_name`, `apply_run_name_template`) with enforced format: `YYYY-MM-DD-<petname>`.
- Wired `--run-name` into `scripts/train_fasttext.py`, `scripts/train_teacher_dapt.py`, `scripts/train_transformer_teacher.py`, and `scripts/train_transformer_student_distill.py`.
- Student distillation now resolves `{run_name}` in `--output-dir`, writes artifacts under the resolved path, and records `run_name` in `student_config.json`.
- Verified parser surfaces the new flag on all four scripts via `--help`.
- Verified helper behavior in `scripts/.venv`:
  - `resolve_run_name(None)` -> `2026-02-15-<petname>`
  - `resolve_run_name("flying-narwhal")` -> `2026-02-15-flying-narwhal`

## 15:59

Cloned Hugging Face experiments repo for handoff workflow:
- local path: /home/bob/offline/janitr-experiments
- origin: https://huggingface.co/janitr/experiments
- current branch: main
This will be the staging location to copy model artifacts before user pulls to their local machine and performs HF upload.

Validated model handoff copy plan into Hugging Face experiments clone with dry-run:
- Command: python3 scripts/sync_to_experiments_repo.py --dest-root ~/offline/janitr-experiments --run-id 2026-02-15-flying-narwhal --dry-run
- Result: planned 9-file copy into runs/2026-02-15-flying-narwhal (model + tokenizer + thresholds + eval).

Committed and pushed dated run naming + experiments sync tooling updates.

- Commit: 19a2600 (feat/tiny-transformer-impl)
- Includes: auto `YYYY-MM-DD-<petname>` run-name helper, `--run-name` wiring across fastText/teacher/DAPT/student scripts, and sync helpers (`sync_to_experiments_repo.py`, `sync_experiments_from_remote.sh`).
- Pushed to origin branch: feat/tiny-transformer-impl

## 16:06

Added new repo-local skill: `.agent/skills/huggingface/SKILL.md`.

Content captures the canonical Hugging Face experiments workflow:
- remote staging via `scripts/sync_to_experiments_repo.py`
- default remote->local sync via `scripts/sync_experiments_from_remote.sh` without `--run-id`
- optional dry-run and optional single-run sync
- local commit/push steps from `~/offline/janitr-experiments`
Also clarified that repo skills live under `.agent/skills` while `/home/bob/.codex/skills` currently only contains system skills.
