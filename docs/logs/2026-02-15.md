---
title: Daily Log 2026-02-15
author: bob <unknown@example.com>
date: 2026-02-15
tz: Europe/Berlin
created: 2026-02-15T00:08:59+01:00
last_section: 2026-02-15T09:36:49+01:00
updated: 2026-02-15T09:41:08+01:00
---

## 00:08

Compared small transformer (`h128_l4_a4_i512`, int8 eval at `/tmp/small_h128_holdout_eval_int8.json`) against baseline transformer benchmark (`models/benchmarks/2026-02-14_expanded_holdout/transformer/student_holdout_eval_int8.json`).

Observed large gains on the shared holdout support (scam=245, clean=506, topic_crypto=318): scam recall +32.24 pts, scam F1 +21.74 pts, macro F1 +16.28 pts, exact match +14.22 pts, and lower scam FPR by 0.73 pts.

Flagged as likely needing provenance validation because gain magnitude is unusually large versus earlier transformer comparisons.

## 09:13

Backed up full local `models/` directory before commit/push to `/home/bob/model_backups/janitr_models_20260215_091229` (~32G snapshot).

Prepared commit including `data/split_backups/2026-02-14-holdout-expand/*` and todayâ€™s SimpleLog updates.

Per request, deleted oversized backup `/home/bob/model_backups/janitr_models_20260215_091229` and replaced it with a minimal backup containing only the deployable 2.0MB student int8 ONNX artifact.

New backup path: `/home/bob/model_backups/janitr_small_int8_20260215_091611/student.int8.onnx`.

## 09:30

Implemented dual-backend extension inference plumbing so Janitr can run `fasttext`, `transformer`, or `auto` backend selection without replacing the current flow.

Code changes:
- `extension/background.js`: added persisted backend config (`ic_model_backend`) via extension storage, plus runtime messages `ic-set-model-backend` and `ic-get-model-backend`; inference messages now forward selected engine to offscreen.
- `extension/offscreen.js`: added engine router with fastText path, transformer path, and `auto` fallback behavior (transformer first, then fastText if transformer fails).
- `extension/transformer/scam-detector-transformer.js` (new): ONNX runtime wrapper + BERT WordPiece tokenizer implementation in browser JS; outputs compatible Janitr result schema (`label`, `labels`, `scores`, `probability`, thresholds).
- `extension/manifest.json`: added `storage` permission and web-accessible paths for transformer/runtime assets.
- `extension/content-script.js`: now records returned inference engine/fallback metadata in debug logs.
- `.gitignore`: added ONNX/WASM binary ignore patterns.

Validation:
- Syntax checks passed with `node --check` for updated JS files.
- Playwright smoke test could not run in this environment because Chromium binary is not installed (`npx playwright install` required).

Staged local (git-ignored) transformer extension assets to make dual-backend path runnable without committing binaries:
- `extension/transformer/student.int8.onnx`
- `extension/transformer/thresholds.json`
- `extension/transformer/student_config.json`
- `extension/transformer/tokenizer/vocab.txt`
- `extension/vendor/onnxruntime-web/{ort.wasm.min.mjs,ort-wasm-simd-threaded.mjs,ort-wasm-simd-threaded.wasm}`

Updated `.gitignore` to keep these runtime/model artifacts local-only while allowing source code commits.

Attempted Node-based direct smoke run of transformer module; it failed on `fetch(file://...)` due Node undici file-scheme limitation. This does not block extension runtime (uses `chrome-extension://` URLs), but browser-side validation is still required.

## 09:36

Confirmed backend behavior: `auto` mode selects transformer first and falls back to fastText only on transformer failure.

Refactored extension naming to general classifier terminology:
- Renamed `extension/fasttext/scam-detector.js` -> `extension/fasttext/classifier.js`
- Renamed `extension/transformer/scam-detector-transformer.js` -> `extension/transformer/classifier-transformer.js`
- Renamed exports/usages to neutral API (`loadClassifierModel`, `loadClassifierThresholds`, `predictClassifier`, `resetClassifierModel`, `predictTransformerBatch`)
- Updated content-script UI/debug strings from "Scam model"/"Scam detector inference failed" to generic classifier phrasing and renamed confidence data attribute to `data-ic-confidence`
- Updated smoke tests and AGENTS.md references to new classifier names

Behavior remains unchanged aside from naming/output-key normalization (`isFlagged` instead of `isScam`).

Changed extension default classifier backend to transformer by setting `DEFAULT_ENGINE = ENGINE_TRANSFORMER` in `extension/background.js`.

Effect: when no backend is explicitly stored yet, inference requests now default to transformer path (with offscreen auto/explicit behavior unchanged).
